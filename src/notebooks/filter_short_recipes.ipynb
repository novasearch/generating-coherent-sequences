{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RECIPES_FILE = '.json'\n",
    "RESULT_FILE = 'out.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(RECIPES_FILE, \"r\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "def fits_tokenizer(input_text: str) -> bool:\n",
    "    MAX = 77\n",
    "    inputs = tokenizer(input_text, padding=True, return_tensors=\"pt\")\n",
    "    return len(inputs['input_ids'][0]) < MAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data before filtering for tokenizer: 2884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (94 > 77). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after filtering for tokenizer: 2883\n"
     ]
    }
   ],
   "source": [
    "print(f\"Data before filtering for tokenizer: {len(data)}\")\n",
    "\n",
    "recipes_filtered_tokenizer = {recipe_id: _recipe for recipe_id, _recipe in data.items() if all(fits_tokenizer(step_obj[\"stepText\"]) for step_obj in _recipe[\"recipe\"][\"instructions\"])}\n",
    "\n",
    "print(f\"Data after filtering for tokenizer: {len(recipes_filtered_tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_step_length(recipes, words=False):\n",
    "    def num_words(string):\n",
    "        return len(string.split(\" \"))\n",
    "\n",
    "    steps = [step[\"stepText\"] for _, _recipe in recipes.items() for step in _recipe[\"recipe\"][\"instructions\"]]\n",
    "\n",
    "    total_avg = sum(map(num_words if words else len, steps)) / len(steps)\n",
    "\n",
    "    return total_avg\n",
    "\n",
    "\n",
    "def average_number_steps(recipes):\n",
    "        steps = [len(_recipe[\"recipe\"][\"instructions\"]) for _, _recipe in recipes.items()]\n",
    "\n",
    "        total_avg = sum(steps) / len(steps)\n",
    "\n",
    "        return total_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_recipe_num_steps(recipes, target_steps=5, window=1):\n",
    "    return { recipe_id: _recipe for recipe_id, _recipe in recipes.items() if target_steps - window <= len(_recipe[\"recipe\"][\"instructions\"]) <= target_steps + window }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes_filtered_num_steps = filter_recipe_num_steps(data, target_steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_recipes = filter_recipe_num_steps(recipes_filtered_tokenizer, target_steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Recipes: 2884.\n",
      "Average Step Length: 90.81410020072919.\n",
      "Average Step #Words: 16.29822620949572.\n",
      "Average #Steps: 8.464285714285714.\n",
      "----------\n",
      "Recipes Filtered for Step Length: 2883.\n",
      "Average Step Length: 90.81120399967216.\n",
      "Average Step #Words: 16.297926399475454.\n",
      "Average #Steps: 8.464099895941727.\n",
      "----------\n",
      "Recipes Filtered for #Steps: 822.\n",
      "Average Step Length: 91.64038231780167.\n",
      "Average Step #Words: 16.194982078853048.\n",
      "Average #Steps: 5.091240875912408.\n",
      "----------\n",
      "Recipes Filtered for Step Length and #Steps: 822.\n",
      "Average Step Length: 91.64038231780167.\n",
      "Average Step #Words: 16.194982078853048.\n",
      "Average #Steps: 5.091240875912408.\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "def print_info(recipes, recipe_type):\n",
    "    print(f\"{recipe_type}: {len(recipes)}.\\n\"\n",
    "          f\"Average Step Length: {average_step_length(recipes)}.\\n\"\n",
    "          f\"Average Step #Words: {average_step_length(recipes, words=True)}.\\n\"\n",
    "          f\"Average #Steps: {average_number_steps(recipes)}.\")\n",
    "    print(\"-\" * 10)\n",
    "\n",
    "for r, t in [(data, \"Original Recipes\"), (recipes_filtered_tokenizer, \"Recipes Filtered for Step Length\"), \n",
    "             (recipes_filtered_num_steps, \"Recipes Filtered for #Steps\"), (filtered_recipes, \"Recipes Filtered for Step Length and #Steps\")]:\n",
    "    print_info(r, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(RESULT_FILE, \"w\") as f:\n",
    "    json.dump(filtered_recipes, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
